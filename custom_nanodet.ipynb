{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ9i5P42Drpr"
      },
      "source": [
        "# Train NanoDet with custom dataset\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/SonySemiconductorSolutions/aitrios-rpi-tutorials-ai-model-training/blob/main/notebooks/nanodet-ppe/custom_nanodet.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Training NanoDet model to detect Personal Protection Equipment (PPE) using open source dataset.\n",
        "\n",
        "Nanodet training based on https://github.com/RangiLyu/nanodet/tree/main\n",
        "\n",
        "Tutorial includes:\n",
        "- Dataset setup\n",
        "- Nanodet model setup\n",
        "- Training\n",
        "- Quantization using [Model Compression Toolkit - MCT](https://github.com/sony/model_optimization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J3klfxbaDrpt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch==1.13.1+cu117 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (1.13.1+cu117)\n",
            "Requirement already satisfied: torchvision==0.14.1+cu117 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (0.14.1+cu117)\n",
            "Requirement already satisfied: torchaudio==0.13.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (0.13.1+cu117)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from torch==1.13.1+cu117) (4.12.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from torchvision==0.14.1+cu117) (1.26.4)\n",
            "Requirement already satisfied: requests in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from torchvision==0.14.1+cu117) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from torchvision==0.14.1+cu117) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision==0.14.1+cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision==0.14.1+cu117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision==0.14.1+cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests->torchvision==0.14.1+cu117) (2025.1.31)\n",
            "Requirement already satisfied: model-compression-toolkit in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: roboflow in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (1.1.53)\n",
            "Requirement already satisfied: networkx!=2.8.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (3.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (4.67.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (11.1.0)\n",
            "Requirement already satisfied: numpy<2.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (0.24.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (1.6.1)\n",
            "Requirement already satisfied: tensorboard in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (2.14.1)\n",
            "Requirement already satisfied: PuLP in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (2.9.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (3.9.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (1.13.1)\n",
            "Requirement already satisfied: protobuf in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (4.25.3)\n",
            "Requirement already satisfied: mct-quantizers==1.5.2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from model-compression-toolkit) (1.5.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from mct-quantizers==1.5.2->model-compression-toolkit) (24.2)\n",
            "Requirement already satisfied: certifi in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (2025.1.31)\n",
            "Requirement already satisfied: idna==3.7 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tqdm->model-compression-toolkit) (0.4.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib->model-compression-toolkit) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib->model-compression-toolkit) (4.56.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib->model-compression-toolkit) (3.2.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from matplotlib->model-compression-toolkit) (6.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests->roboflow) (3.4.1)\n",
            "Requirement already satisfied: imageio>=2.33 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from scikit-image->model-compression-toolkit) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from scikit-image->model-compression-toolkit) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from scikit-image->model-compression-toolkit) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from scikit-learn->model-compression-toolkit) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from scikit-learn->model-compression-toolkit) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (1.70.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (75.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard->model-compression-toolkit) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->model-compression-toolkit) (2.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->model-compression-toolkit) (3.21.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from markdown>=2.6.8->tensorboard->model-compression-toolkit) (8.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->model-compression-toolkit) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->model-compression-toolkit) (3.2.2)\n",
            "Requirement already satisfied: tensorflow==2.14 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (2.14.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow==2.14) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow==2.14) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow==2.14) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (8.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.21.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\peter\\miniconda3\\envs\\nanodet\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow==2.14) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install model-compression-toolkit roboflow\n",
        "!pip install \"tensorflow==2.14\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i99PvxYNDrpu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total memory: 31.88GB\n",
            "[]\n",
            "Is cuda available: True\n"
          ]
        }
      ],
      "source": [
        "# Perform initial checks in order to continue\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "assert '2.14' in tf.__version__, print(tf.__version__)\n",
        "assert '1.13' in torch.__version__, print(torch.__version__)\n",
        "\n",
        "# Check available memory\n",
        "mem = psutil.virtual_memory()\n",
        "mem_in_gb = mem.total / (1024 ** 3)\n",
        "print(f\"Total memory: {mem_in_gb:.2f}GB\")\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(f'Is cuda available: {torch.cuda.is_available()}')\n",
        "assert mem_in_gb >= 12 or torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPTlH8kCDrpu"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DNOMoOs1Drpu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'nanodet'...\n",
            "Note: switching to 'be9b4a9'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at be9b4a9 Replaced opencv with imagesize to get the actual image size (#548)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Known errors:\n",
        "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
        "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
        "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
        "\"\"\"\n",
        "NANODET_COMMIT = 'be9b4a9'\n",
        "!git clone https://github.com/RangiLyu/nanodet.git\n",
        "!type NUL > nanodet/nanodet/model/__init__.py\n",
        "!cd nanodet && git checkout {NANODET_COMMIT} && pip install -q --no-cache-dir -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9Vg7BdDrpv"
      },
      "source": [
        "# Dataset\n",
        "- go to https://universe.roboflow.com/ai-camp-safety-equipment-detection/ppe-detection-using-cv/dataset/3 and click `\"Download Dataset\"`\n",
        "- choose format `\"COCO\"` and `\"show download code\"` and `\"continue\"`\n",
        "- choose `\"Terminal\"` and copy the command `\"curl...\"` and paste the command in the cell below.\n",
        "- add `\"!\"` in the beginning of the command and replace `\"\\&gt;\"` with `\">\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PLwVnk7jDrpv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Rock-Detection-1 to coco:: 100%|██████████| 537938/537938 [00:15<00:00, 34004.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Rock-Detection-1 in coco:: 100%|██████████| 7373/7373 [00:03<00:00, 1962.36it/s]\n"
          ]
        }
      ],
      "source": [
        "# Add below your download code from Roboflow, it should look like the following, with your unique roboflow dataset url:\n",
        "# Example (with \"!\" added in the beginning of the command and replaced \"&gt;\" with \">\". Also added \"-q\" for less output):\n",
        "# !curl -L \"https://universe.roboflow.com/ds/<unique-dataset-url>\" > roboflow.zip; unzip -q roboflow.zip; rm roboflow.zip\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "rf = Roboflow(os.getenv(\"roboflow\"))\n",
        "project = rf.workspace(\"rocks-rkbw8\").project(\"rock-detection-dvadl\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")\n",
        "                \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2buLovTuDrpv"
      },
      "outputs": [],
      "source": [
        "# Move test/train/valid to dataset folder\n",
        "from pathlib import Path\n",
        "DATASET_PATH = 'Rock-Detection-1'\n",
        "if not Path(f'{DATASET_PATH}/train/_annotations.coco.json').exists():\n",
        "    assert Path(f'train/_annotations.coco.json').exists()\n",
        "    assert Path(f'valid/_annotations.coco.json').exists()\n",
        "    assert Path(f'test/_annotations.coco.json').exists()\n",
        "    !mkdir -p $DATASET_PATH\n",
        "    !mv test train valid *txt $DATASET_PATH/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "60bRlp2qDrpx"
      },
      "outputs": [],
      "source": [
        "assert Path(f'{DATASET_PATH}/train/_annotations.coco.json').exists()\n",
        "assert Path(f'{DATASET_PATH}/valid/_annotations.coco.json').exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYr5Zy4gDrpx"
      },
      "source": [
        "# Training config file: nanodet-plus-m-1.5x_416-ppe.yml\n",
        "The following block of code creates the NanoDet training config file which\n",
        "is based on nanodet/config/nanodet-plus-m-1.5x_416.yml.\n",
        "Updated for the custom PPE dataset\n",
        "Change number of `total_epochs` for better performance.\n",
        "\n",
        "If training on GPU, then set   `gpu_ids`:\n",
        " * 1 gpu: [0]\n",
        " * 2 gpu: [0,1]\n",
        " * etc...\n",
        "\n",
        "Increase `total_epochs`, for example 20.\n",
        "\n",
        "Feel free to increase `val_intervals`, for example 10.\n",
        "\n",
        "For details see NanoDet github repo and [config docs](https://github.com/RangiLyu/nanodet/blob/main/docs/config_file_detail.md). Observe recommendation to adjust `lr` with `batch_size`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5dGnKuBDrpx"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2h5AeLoiDrpx"
      },
      "outputs": [],
      "source": [
        "# OBSERVE: update the following assert statement to match your yml file settings.\n",
        "\n",
        "import yaml\n",
        "with open('nanodet-plus-m-1.5x_416-ppe.yml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "assert config['device']['gpu_ids'] == -1 or config['device']['gpu_ids'] == [0], print(f\"gpu_ids: {config['device']['gpu_ids']}\")\n",
        "assert config['schedule']['total_epochs'] == 2 or config['schedule']['total_epochs'] == 20, print(f\"total_epochs: {config['schedule']['total_epochs']}\")\n",
        "assert config['schedule']['val_intervals'] == 1 or config['schedule']['val_intervals'] == 10, print(f\"val_intervals: {config['schedule']['val_intervals']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Names: ['Rocks-lAGt', 'Float_Rock', 'stone']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to your COCO annotations file\n",
        "annotations_path = Path('Rock-Detection-1/train/_annotations.coco.json')\n",
        "\n",
        "# Load the annotations\n",
        "with open(annotations_path, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Extract class names\n",
        "categories = annotations.get('categories', [])\n",
        "class_names = [category['name'] for category in categories]\n",
        "\n",
        "print(\"Class Names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wcrhPkc7Drpy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "model size is  1.5x\n",
            "init weights...\n",
            "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth\n",
            "Finish initialize NanoDet-Plus Head.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:38:16]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSetting up data...\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:38:16]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mCreating model...\u001b[0m\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type        | Params\n",
            "------------------------------------------\n",
            "0 | model     | NanoDetPlus | 7.7 M \n",
            "1 | avg_model | NanoDetPlus | 7.7 M \n",
            "------------------------------------------\n",
            "15.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "15.5 M    Total params\n",
            "61.960    Total estimated model params size (MB)\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:38:16]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mWeight Averaging is enabled\u001b[0m\n",
            "C:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "C:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "C:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:38:29]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter0(1/211)| mem:7.93G| lr:1.00e-07| loss_qfl:0.7725| loss_bbox:1.0287| loss_dfl:0.5204| aux_loss_qfl:0.6902| aux_loss_bbox:0.9967| aux_loss_dfl:0.5259| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:39:15]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter10(11/211)| mem:8.24G| lr:2.01e-05| loss_qfl:0.9415| loss_bbox:0.9320| loss_dfl:0.5201| aux_loss_qfl:0.5979| aux_loss_bbox:0.8796| aux_loss_dfl:0.4858| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:39:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter20(21/211)| mem:8.24G| lr:4.01e-05| loss_qfl:1.1441| loss_bbox:0.8539| loss_dfl:0.5159| aux_loss_qfl:0.5128| aux_loss_bbox:0.7785| aux_loss_dfl:0.4313| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:40:14]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter30(31/211)| mem:8.24G| lr:6.01e-05| loss_qfl:1.0261| loss_bbox:0.9304| loss_dfl:0.5128| aux_loss_qfl:0.4411| aux_loss_bbox:0.8231| aux_loss_dfl:0.4358| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:40:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter40(41/211)| mem:8.24G| lr:8.01e-05| loss_qfl:1.0322| loss_bbox:0.9280| loss_dfl:0.5033| aux_loss_qfl:0.4062| aux_loss_bbox:0.7589| aux_loss_dfl:0.4193| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:41:13]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter50(51/211)| mem:8.24G| lr:1.00e-04| loss_qfl:1.0894| loss_bbox:0.8990| loss_dfl:0.4798| aux_loss_qfl:0.4335| aux_loss_bbox:0.7064| aux_loss_dfl:0.3960| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:41:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter60(61/211)| mem:8.24G| lr:1.20e-04| loss_qfl:0.9132| loss_bbox:0.7851| loss_dfl:0.4433| aux_loss_qfl:0.4031| aux_loss_bbox:0.6497| aux_loss_dfl:0.3732| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:42:13]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter70(71/211)| mem:8.24G| lr:1.40e-04| loss_qfl:0.8875| loss_bbox:0.7368| loss_dfl:0.4115| aux_loss_qfl:0.3653| aux_loss_bbox:0.5627| aux_loss_dfl:0.3329| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:42:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter80(81/211)| mem:8.24G| lr:1.60e-04| loss_qfl:0.8110| loss_bbox:0.7116| loss_dfl:0.4100| aux_loss_qfl:0.4420| aux_loss_bbox:0.5780| aux_loss_dfl:0.3432| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:43:14]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter90(91/211)| mem:8.24G| lr:1.80e-04| loss_qfl:0.7066| loss_bbox:0.7582| loss_dfl:0.4131| aux_loss_qfl:0.3827| aux_loss_bbox:0.6014| aux_loss_dfl:0.3376| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:43:43]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter100(101/211)| mem:8.24G| lr:2.00e-04| loss_qfl:0.6372| loss_bbox:0.7495| loss_dfl:0.4124| aux_loss_qfl:0.3783| aux_loss_bbox:0.5122| aux_loss_dfl:0.3038| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:44:14]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter110(111/211)| mem:8.24G| lr:2.20e-04| loss_qfl:0.5485| loss_bbox:0.7517| loss_dfl:0.4215| aux_loss_qfl:0.3715| aux_loss_bbox:0.5210| aux_loss_dfl:0.3105| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:44:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter120(121/211)| mem:8.24G| lr:2.40e-04| loss_qfl:0.5222| loss_bbox:0.7383| loss_dfl:0.4135| aux_loss_qfl:0.3818| aux_loss_bbox:0.4977| aux_loss_dfl:0.2982| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:45:17]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter130(131/211)| mem:8.24G| lr:2.60e-04| loss_qfl:0.5858| loss_bbox:0.7205| loss_dfl:0.4023| aux_loss_qfl:0.3693| aux_loss_bbox:0.4652| aux_loss_dfl:0.2781| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:45:51]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter140(141/211)| mem:8.24G| lr:2.80e-04| loss_qfl:0.4713| loss_bbox:0.5945| loss_dfl:0.3827| aux_loss_qfl:0.3986| aux_loss_bbox:0.4259| aux_loss_dfl:0.2692| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:46:24]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter150(151/211)| mem:8.24G| lr:3.00e-04| loss_qfl:0.4840| loss_bbox:0.6548| loss_dfl:0.3885| aux_loss_qfl:0.3610| aux_loss_bbox:0.4959| aux_loss_dfl:0.2839| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:46:57]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter160(161/211)| mem:8.24G| lr:3.20e-04| loss_qfl:0.4673| loss_bbox:0.5962| loss_dfl:0.3729| aux_loss_qfl:0.4090| aux_loss_bbox:0.4258| aux_loss_dfl:0.2541| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:47:30]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter170(171/211)| mem:8.24G| lr:3.40e-04| loss_qfl:0.3219| loss_bbox:0.5947| loss_dfl:0.3667| aux_loss_qfl:0.2908| aux_loss_bbox:0.4072| aux_loss_dfl:0.2416| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:48:04]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter180(181/211)| mem:8.24G| lr:3.60e-04| loss_qfl:0.3667| loss_bbox:0.5338| loss_dfl:0.3612| aux_loss_qfl:0.3428| aux_loss_bbox:0.3820| aux_loss_dfl:0.2444| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:48:38]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter190(191/211)| mem:8.24G| lr:3.80e-04| loss_qfl:0.4291| loss_bbox:0.5773| loss_dfl:0.3610| aux_loss_qfl:0.3505| aux_loss_bbox:0.4385| aux_loss_dfl:0.2556| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:49:11]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter200(201/211)| mem:8.24G| lr:4.00e-04| loss_qfl:0.3423| loss_bbox:0.5329| loss_dfl:0.3529| aux_loss_qfl:0.3195| aux_loss_bbox:0.4447| aux_loss_dfl:0.2614| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:49:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch1/2|Iter210(211/211)| mem:8.24G| lr:4.20e-04| loss_qfl:0.3586| loss_bbox:0.5196| loss_dfl:0.3378| aux_loss_qfl:0.3146| aux_loss_bbox:0.3844| aux_loss_dfl:0.2351| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:49:54]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal|Epoch1/2|Iter211(1/13)| mem:8.24G| lr:4.20e-04| loss_qfl:0.3646| loss_bbox:0.4613| loss_dfl:0.3260| aux_loss_qfl:0.3313| aux_loss_bbox:0.3221| aux_loss_dfl:0.2228| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:49:57]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal|Epoch1/2|Iter211(11/13)| mem:8.24G| lr:4.20e-04| loss_qfl:0.2501| loss_bbox:0.4284| loss_dfl:0.3106| aux_loss_qfl:0.2435| aux_loss_bbox:0.3209| aux_loss_dfl:0.2074| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:01]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97m\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
            "\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:01]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97m\n",
            "| class      | AP50   | mAP   | class      | AP50   | mAP   |\n",
            "|:-----------|:-------|:------|:-----------|:-------|:------|\n",
            "| Rocks-lAGt | nan    | nan   | Float_Rock | 10.4   | 3.8   |\n",
            "| stone      | 85.8   | 53.2  |            |        |       |\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:02]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSaving model to workspace/nanodet-plus-m-1.5x_416-ppe\\model_best\\nanodet_model_best.pth\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:02]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal_metrics: {'mAP': 0.2847211119324912, 'AP_50': 0.4811259667564675, 'AP_75': 0.2986762824229542, 'AP_small': 0.0, 'AP_m': 0.10035567986828794, 'AP_l': 0.3734726499381696}\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:19]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter220(10/211)| mem:8.23G| lr:4.40e-04| loss_qfl:0.3707| loss_bbox:0.5304| loss_dfl:0.3358| aux_loss_qfl:0.3385| aux_loss_bbox:0.4499| aux_loss_dfl:0.2561| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:27]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter230(20/211)| mem:8.23G| lr:4.60e-04| loss_qfl:0.3753| loss_bbox:0.4686| loss_dfl:0.3252| aux_loss_qfl:0.3319| aux_loss_bbox:0.3819| aux_loss_dfl:0.2356| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:35]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter240(30/211)| mem:8.24G| lr:4.80e-04| loss_qfl:0.3513| loss_bbox:0.4829| loss_dfl:0.3218| aux_loss_qfl:0.3092| aux_loss_bbox:0.3817| aux_loss_dfl:0.2430| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:44]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter250(40/211)| mem:8.24G| lr:5.00e-04| loss_qfl:0.3299| loss_bbox:0.4729| loss_dfl:0.3079| aux_loss_qfl:0.3038| aux_loss_bbox:0.4126| aux_loss_dfl:0.2328| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:50:52]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter260(50/211)| mem:8.24G| lr:5.20e-04| loss_qfl:0.3836| loss_bbox:0.4777| loss_dfl:0.3237| aux_loss_qfl:0.3334| aux_loss_bbox:0.3973| aux_loss_dfl:0.2518| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:00]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter270(60/211)| mem:8.24G| lr:5.40e-04| loss_qfl:0.3520| loss_bbox:0.5135| loss_dfl:0.3144| aux_loss_qfl:0.3238| aux_loss_bbox:0.4287| aux_loss_dfl:0.2466| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:09]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter280(70/211)| mem:8.24G| lr:5.60e-04| loss_qfl:0.3560| loss_bbox:0.4488| loss_dfl:0.3010| aux_loss_qfl:0.3282| aux_loss_bbox:0.3828| aux_loss_dfl:0.2451| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:17]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter290(80/211)| mem:8.24G| lr:5.80e-04| loss_qfl:0.3976| loss_bbox:0.4624| loss_dfl:0.3003| aux_loss_qfl:0.3845| aux_loss_bbox:0.3993| aux_loss_dfl:0.2381| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:25]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter300(90/211)| mem:8.24G| lr:6.00e-04| loss_qfl:0.4218| loss_bbox:0.4172| loss_dfl:0.2920| aux_loss_qfl:0.3691| aux_loss_bbox:0.3472| aux_loss_dfl:0.2284| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:34]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter310(100/211)| mem:8.24G| lr:6.20e-04| loss_qfl:0.3149| loss_bbox:0.4823| loss_dfl:0.2995| aux_loss_qfl:0.3019| aux_loss_bbox:0.4094| aux_loss_dfl:0.2348| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:42]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter320(110/211)| mem:8.24G| lr:6.40e-04| loss_qfl:0.2967| loss_bbox:0.4586| loss_dfl:0.2862| aux_loss_qfl:0.2690| aux_loss_bbox:0.3912| aux_loss_dfl:0.2384| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:50]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter330(120/211)| mem:8.24G| lr:6.60e-04| loss_qfl:0.3266| loss_bbox:0.4086| loss_dfl:0.2689| aux_loss_qfl:0.2832| aux_loss_bbox:0.3633| aux_loss_dfl:0.2286| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:51:59]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter340(130/211)| mem:8.24G| lr:6.80e-04| loss_qfl:0.3563| loss_bbox:0.4306| loss_dfl:0.2767| aux_loss_qfl:0.3243| aux_loss_bbox:0.3838| aux_loss_dfl:0.2340| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:07]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter350(140/211)| mem:8.24G| lr:7.00e-04| loss_qfl:0.2662| loss_bbox:0.4096| loss_dfl:0.2668| aux_loss_qfl:0.2433| aux_loss_bbox:0.3569| aux_loss_dfl:0.2223| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:15]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter360(150/211)| mem:8.24G| lr:7.20e-04| loss_qfl:0.3331| loss_bbox:0.4312| loss_dfl:0.2709| aux_loss_qfl:0.3017| aux_loss_bbox:0.3690| aux_loss_dfl:0.2358| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:24]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter370(160/211)| mem:8.24G| lr:7.40e-04| loss_qfl:0.3042| loss_bbox:0.4571| loss_dfl:0.2788| aux_loss_qfl:0.3095| aux_loss_bbox:0.3746| aux_loss_dfl:0.2401| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:32]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter380(170/211)| mem:8.24G| lr:7.60e-04| loss_qfl:0.3105| loss_bbox:0.4572| loss_dfl:0.2662| aux_loss_qfl:0.3028| aux_loss_bbox:0.3794| aux_loss_dfl:0.2284| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:40]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter390(180/211)| mem:8.24G| lr:7.80e-04| loss_qfl:0.3336| loss_bbox:0.4295| loss_dfl:0.2681| aux_loss_qfl:0.3421| aux_loss_bbox:0.3778| aux_loss_dfl:0.2417| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:49]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter400(190/211)| mem:8.24G| lr:8.00e-04| loss_qfl:0.3678| loss_bbox:0.4244| loss_dfl:0.2645| aux_loss_qfl:0.3496| aux_loss_bbox:0.4230| aux_loss_dfl:0.2448| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:52:57]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter410(200/211)| mem:8.24G| lr:8.20e-04| loss_qfl:0.2986| loss_bbox:0.4040| loss_dfl:0.2577| aux_loss_qfl:0.2966| aux_loss_bbox:0.3898| aux_loss_dfl:0.2364| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:05]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mTrain|Epoch2/2|Iter420(210/211)| mem:8.24G| lr:8.40e-04| loss_qfl:0.2976| loss_bbox:0.3982| loss_dfl:0.2499| aux_loss_qfl:0.3139| aux_loss_bbox:0.3568| aux_loss_dfl:0.2271| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:14]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal|Epoch2/2|Iter422(1/13)| mem:8.24G| lr:8.42e-04| loss_qfl:0.3042| loss_bbox:0.3559| loss_dfl:0.2377| aux_loss_qfl:0.2705| aux_loss_bbox:0.2813| aux_loss_dfl:0.1996| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:18]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal|Epoch2/2|Iter422(11/13)| mem:8.24G| lr:8.42e-04| loss_qfl:0.2294| loss_bbox:0.3369| loss_dfl:0.2194| aux_loss_qfl:0.2229| aux_loss_bbox:0.2673| aux_loss_dfl:0.1884| \u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:22]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97m\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.591\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
            "\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:22]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97m\n",
            "| class      | AP50   | mAP   | class      | AP50   | mAP   |\n",
            "|:-----------|:-------|:------|:-----------|:-------|:------|\n",
            "| Rocks-lAGt | nan    | nan   | Float_Rock | 22.7   | 7.6   |\n",
            "| stone      | 95.5   | 65.1  |            |        |       |\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:22]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mSaving model to workspace/nanodet-plus-m-1.5x_416-ppe\\model_best\\nanodet_model_best.pth\u001b[0m\n",
            "\u001b[1m\u001b[35m[NanoDet]\u001b[0m\u001b[34m[02-08 19:53:22]\u001b[0m\u001b[32mINFO:\u001b[0m\u001b[97mVal_metrics: {'mAP': 0.36368159687884577, 'AP_50': 0.5906141616867262, 'AP_75': 0.399912997196624, 'AP_small': 0.01089108910891089, 'AP_m': 0.2157023287343637, 'AP_l': 0.43414885002299625}\u001b[0m\n",
            "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ],
      "source": [
        "'''import torch\n",
        "assert '1.13' in torch.__version__, print(torch.__version__)\n",
        "assert Path('nanodet-plus-m-1.5x_416-ppe.yml').exists()\n",
        "!export PYTHONPATH=$PWD/nanodet:$PYTHONPATH && python nanodet/tools/train.py nanodet-plus-m-1.5x_416-ppe.yml'''\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "assert '1.13' in torch.__version__, print(torch.__version__)\n",
        "assert Path('nanodet-plus-m-1.5x_416-ppe.yml').exists()\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}/nanodet;{os.environ.get('PYTHONPATH', '')}\"\n",
        "\n",
        "\n",
        "#sometime i should make this work without a shell command\n",
        "!\"python.exe\" ../nanodet/tools/train.py nanodet-plus-m-1.5x_416-ppe.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAGKkgADrpy"
      },
      "source": [
        "# Remove aux layers that are only used during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MSjjx2k7Drpy"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"./nanodet\")\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "from nanodet.model.arch import build_model\n",
        "from nanodet.util import cfg, load_config, Logger\n",
        "\n",
        "def remove_aux(cfg, model_path, remove_layers=['aux_fpn', 'aux_head'], debug=False):\n",
        "    model = build_model(cfg.model)\n",
        "    ckpt = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "    if len(remove_layers) > 0:\n",
        "        state_dict = copy.deepcopy(ckpt['state_dict'])\n",
        "        for rlayer in remove_layers:\n",
        "            for layer in ckpt['state_dict']:\n",
        "                if rlayer in layer:\n",
        "                    del state_dict[layer]\n",
        "                    if debug:\n",
        "                        print(f'removed layer: {layer}')\n",
        "        del ckpt['state_dict']\n",
        "        ckpt['state_dict'] = copy.deepcopy(state_dict)\n",
        "        del state_dict\n",
        "    return ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gGMLsP-HDrpy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size is  1.5x\n",
            "init weights...\n",
            "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth\n",
            "Finish initialize NanoDet-Plus Head.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model_best/nanodet_model_best.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_best/nanodet_model_best-removed-aux.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m load_config(cfg, config_path)\n\u001b[1;32m----> 9\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mremove_aux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maux_fpn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maux_head\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(ckpt, dst_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdst_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[11], line 11\u001b[0m, in \u001b[0;36mremove_aux\u001b[1;34m(cfg, model_path, remove_layers, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mremove_aux\u001b[39m(cfg, model_path, remove_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_fpn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_head\u001b[39m\u001b[38;5;124m'\u001b[39m], debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(cfg\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m---> 11\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(remove_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\torch\\serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\Peter\\miniconda3\\envs\\nanodet\\lib\\site-packages\\torch\\serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_best/nanodet_model_best.pth'"
          ]
        }
      ],
      "source": [
        "config_path = 'nanodet-plus-m-1.5x_416-ppe.yml'\n",
        "model_path = 'workspace/nanodet-plus-m-1.5x_416-ppe/model_best/nanodet_model_best.pth'\n",
        "model_path = 'model_best/nanodet_model_best.pth'\n",
        "\n",
        "dst_path = 'workspace/nanodet-plus-m-1.5x_416-ppe/model_best/nanodet_model_best-removed-aux.pth'\n",
        "dst_path = 'model_best/nanodet_model_best-removed-aux.pth'\n",
        "\n",
        "load_config(cfg, config_path)\n",
        "ckpt = remove_aux(cfg, model_path, ['aux_fpn', 'aux_head'])\n",
        "torch.save(ckpt, dst_path)\n",
        "print(f'Saved to: {dst_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeErUxzDrpy"
      },
      "outputs": [],
      "source": [
        "# Compare size w and w/o aux\n",
        "!ls -l workspace/nanodet-plus-m-1.5x_416-ppe/model_best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmcWZlG6Drpy"
      },
      "source": [
        "# Quantization of custom NanoDet model using Model Compression Toolkit\n",
        "Quantization is based on https://github.com/sony/model_optimization/blob/v2.0.0/tutorials/notebooks/keras/ptq/example_keras_nanodet_plus.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10VG47s1Drpy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7XRbKu_Drpy"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "MCT_COMMIT = 'v2.1.0'\n",
        "!git clone https://github.com/sony/model_optimization.git local_mct && cd local_mct && git checkout {MCT_COMMIT} && pip install --no-cache-dir -r requirements.txt\n",
        "sys.path.insert(0,\"./local_mct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLM07WTrDrpy"
      },
      "source": [
        "# Keras NanoDet float model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuBcFG9TDrpy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "assert '2.14' in tf.__version__, print(tf.__version__)\n",
        "assert '1.13' in torch.__version__, print(torch.__version__)\n",
        "\n",
        "from keras.models import Model\n",
        "import model_compression_toolkit as mct\n",
        "from tutorials.mct_model_garden.models_keras.nanodet.nanodet_keras_model import nanodet_plus_m\n",
        "from tutorials.mct_model_garden.models_keras.utils.torch2keras_weights_translation import load_state_dict\n",
        "from tutorials.mct_model_garden.models_keras.nanodet.nanodet_keras_model import nanodet_box_decoding\n",
        "assert 'local_mct' in mct.__file__, print(mct.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZOIKXMeDrpz"
      },
      "outputs": [],
      "source": [
        "# Upload the trained custom model\n",
        "CUSTOM_WEIGHTS_FILE = dst_path  # The NanoDet model trained with PPE dataset\n",
        "CLASS_NAMES = ['Rocks-lAGt', 'Float_Rock', 'stone']\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "DATASET_TRAIN = DATASET_PATH\n",
        "ANNOT_TRAIN = DATASET_PATH + '/train/_annotations.coco.json'\n",
        "DATASET_VALID = DATASET_PATH + '/valid'\n",
        "ANNOT_VALID = DATASET_PATH + '/valid/_annotations.coco.json'\n",
        "DATASET_REPR = DATASET_VALID\n",
        "ANNOT_REPR = ANNOT_VALID\n",
        "\n",
        "QUANTIZED_MODEL_NAME = 'nanodet-quant-ppe.keras'\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "N_ITER = 20  # 1 for testing, otherwise 20\n",
        "\n",
        "assert Path(CUSTOM_WEIGHTS_FILE).exists()\n",
        "assert Path(DATASET_REPR).exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgzgUA-NDrpz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model(weights=CUSTOM_WEIGHTS_FILE, num_classes=NUM_CLASSES):\n",
        "    INPUT_RESOLUTION = 416\n",
        "    INPUT_SHAPE = (INPUT_RESOLUTION, INPUT_RESOLUTION, 3)\n",
        "    SCALE_FACTOR = 1.5\n",
        "    BOTTLENECK_RATIO = 0.5\n",
        "    FEATURE_CHANNELS = 128\n",
        "\n",
        "    pretrained_weights = torch.load(weights, map_location=torch.device('cpu'))['state_dict']\n",
        "    # Generate Nanodet base model\n",
        "    model = nanodet_plus_m(INPUT_SHAPE, SCALE_FACTOR, BOTTLENECK_RATIO, FEATURE_CHANNELS, num_classes)\n",
        "\n",
        "    # Set the pre-trained weights\n",
        "    load_state_dict(model, state_dict_torch=pretrained_weights)\n",
        "\n",
        "    # Add Nanodet Box decoding layer (decode the model outputs to bounding box coordinates)\n",
        "    scores, boxes = nanodet_box_decoding(model.output, res=INPUT_RESOLUTION, num_classes=num_classes)\n",
        "\n",
        "    # Add TensorFlow NMS layer\n",
        "    outputs = tf.image.combined_non_max_suppression(\n",
        "        boxes,\n",
        "        scores,\n",
        "        max_output_size_per_class=300,\n",
        "        max_total_size=300,\n",
        "        iou_threshold=0.65,\n",
        "        score_threshold=0.001,\n",
        "        pad_per_class=False,\n",
        "        clip_boxes=False\n",
        "        )\n",
        "\n",
        "    model = Model(model.input, outputs, name='Nanodet_plus_m_1.5x_416')\n",
        "\n",
        "    print('Model is ready for evaluation')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di9_ZkmgDrpz"
      },
      "outputs": [],
      "source": [
        "# known warning:  WARNING: head.distribution_project.project not assigned to keras model !!!\n",
        "float_model = get_model(CUSTOM_WEIGHTS_FILE, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAPoQ6UWDrpz"
      },
      "source": [
        "# PTQ quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKotrfOzDrpz"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Iterator, Tuple, List\n",
        "\n",
        "import cv2\n",
        "from tutorials.mct_model_garden.evaluation_metrics.coco_evaluation import coco_dataset_generator, CocoEval\n",
        "\n",
        "def nanodet_preprocess(x):\n",
        "    img_mean = [103.53, 116.28, 123.675]\n",
        "    img_std = [57.375, 57.12, 58.395]\n",
        "    x = cv2.resize(x, (416, 416))\n",
        "    x = (x - img_mean) / img_std\n",
        "    return x\n",
        "\n",
        "def get_representative_dataset(n_iter: int, dataset_loader: Iterator[Tuple]):\n",
        "    def representative_dataset() -> Iterator[List]:\n",
        "        ds_iter = iter(dataset_loader)\n",
        "        for _ in range(n_iter):\n",
        "            yield [next(ds_iter)[0]]\n",
        "\n",
        "    return representative_dataset\n",
        "\n",
        "def quantization(float_model, dataset, annot, n_iter=N_ITER):\n",
        "    # Load representative dataset\n",
        "    representative_dataset = coco_dataset_generator(dataset_folder=dataset,\n",
        "                                                    annotation_file=annot,\n",
        "                                                    preprocess=nanodet_preprocess,\n",
        "                                                    batch_size=BATCH_SIZE)\n",
        "\n",
        "    tpc = mct.get_target_platform_capabilities('tensorflow', 'imx500')\n",
        "\n",
        "    # Preform post training quantization\n",
        "    quant_model, _ = mct.ptq.keras_post_training_quantization(\n",
        "        float_model,\n",
        "        representative_data_gen=get_representative_dataset(n_iter, representative_dataset),\n",
        "        target_platform_capabilities=tpc)\n",
        "\n",
        "    print('Quantized model is ready')\n",
        "    return quant_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owvFq6f-Drpz"
      },
      "outputs": [],
      "source": [
        "quant_model = quantization(float_model, DATASET_REPR, ANNOT_REPR)\n",
        "print(f'Representative dataset: {DATASET_REPR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GejvJS1-Drpz"
      },
      "outputs": [],
      "source": [
        "# Observe that loading quantized model might require specification of custom layers,\n",
        "# see https://github.com/sony/model_optimization/issues/1104\n",
        "quant_model.save(QUANTIZED_MODEL_NAME)\n",
        "print(f'Quantized model saved: {QUANTIZED_MODEL_NAME}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTzdLgkJDrpz"
      },
      "source": [
        "_todo_: coco evaluation of the custom quantized NanoDet model requires some update to the mct repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3QYYt5iDrpz"
      },
      "source": [
        "# Visualize detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YYUEitHDrpz"
      },
      "outputs": [],
      "source": [
        "# Helper functions for visualization\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_image(image_path: str, preprocess: Callable) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load and preprocess an image from a given file path.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "        preprocess (function): Preprocessing function to apply to the loaded image.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed image.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = preprocess(image)\n",
        "    image = np.expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "# draw a single bounding box onto a numpy array image\n",
        "def draw_bounding_box(img, annotation, scale, class_id, score):\n",
        "    row = scale[0]\n",
        "    col = scale[1]\n",
        "    x_min, y_min = int(annotation[1]*col), int(annotation[0]*row)\n",
        "    x_max, y_max = int(annotation[3]*col), int(annotation[2]*row)\n",
        "\n",
        "    color = (0,255,0)\n",
        "\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 2)\n",
        "    text = f'{int(class_id)}: {score:.2f}'\n",
        "    cv2.putText(img, text, (x_min + 10, y_min + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "# draw all annotation bounding boxes on an image\n",
        "def annotate_image(img, output, scale, quantized_model=False, threshold=0.55):\n",
        "    if quantized_model:\n",
        "        b = output[0].numpy()[0]\n",
        "        s = output[1].numpy()[0]\n",
        "        c = output[2].numpy()[0]\n",
        "    else:\n",
        "        print('Assuming float model')\n",
        "        b = output.nmsed_boxes.numpy()[0]\n",
        "        s = output.nmsed_scores.numpy()[0]\n",
        "        c = output.nmsed_classes.numpy()[0]\n",
        "    for index, row in enumerate(b):\n",
        "        if s[index] > threshold:\n",
        "            #print(f'row: {row}')\n",
        "            id = int(c[index])\n",
        "            draw_bounding_box(img, row, scale, id, s[index])\n",
        "            print(f'class: {CLASS_NAMES[id]} ({id}), score: {s[index]:.2f}')\n",
        "    return {'bbox':b, 'score':s, 'classes':c}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vp3kQGzDrp0"
      },
      "outputs": [],
      "source": [
        "# See appendix for results. For 2 epochs, the bounding boxes are not perfect...\n",
        "# But improves considerably for 20 epochs.\n",
        "test_img = 'rock.jpg'\n",
        "img = load_and_preprocess_image(f'{test_img}', nanodet_preprocess)\n",
        "output = quant_model(img)\n",
        "image = cv2.imread(f'{test_img}')\n",
        "print(f'image shape: {image.shape}')\n",
        "r = annotate_image(image, output, scale=image.shape, quantized_model=True)\n",
        "assert r['score'][0] > 0.5, print(f\"r['score'][0] > 0.5 failed: {r['score'][0]}\")\n",
        "dst = f'annotated.jpg'\n",
        "if cv2.imwrite(dst, image):\n",
        "    print(f'Annotated image saved to: {dst}')\n",
        "else:\n",
        "    print(f'Failed saving annotated image')\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install imx500-converter[tf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!imxconv-tf -i nanodet-quant-ppe.keras -o converted_tf/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwF7cniADrp0"
      },
      "source": [
        "# Next step\n",
        "__OBSERVE__: First, save the quantized model to your local machine. You will need it for the conversion and packaging steps.\n",
        "\n",
        "Next step is to convert and package the model for IMX500. _todo: link to further instructions. This model requires bgr settings in the post-converter._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otzEW-CQDrp0"
      },
      "source": [
        "# Appendix\n",
        "## Results total_epochs=2\n",
        "```\n",
        "[NanoDet][07-12 10:47:40]INFO:\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
        " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\n",
        " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.149\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
        "\n",
        "[NanoDet][07-12 10:47:40]INFO:\n",
        "| class            | AP50   | mAP   | class     | AP50   | mAP   |\n",
        "|:-----------------|:-------|:------|:----------|:-------|:------|\n",
        "| Safety-Equipment | nan    | nan   | Person    | 54.1   | 20.1  |\n",
        "| goggles          | 1.6    | 0.4   | helmet    | 40.3   | 13.4  |\n",
        "| no-goggles       | 6.9    | 2.3   | no-helmet | 0.0    | 0.0   |\n",
        "| no-vest          | 3.9    | 1.0   | vest      | 27.1   | 7.9   |\n",
        "[NanoDet][07-12 10:47:40]INFO:Saving model to workspace/nanodet-plus-m-1.5x_416-ppe/model_best/nanodet_model_best.pth\n",
        "[NanoDet][07-12 10:47:40]INFO:Val_metrics: {'mAP': 0.06442128900684024, 'AP_50': 0.1912998265318579, 'AP_75': 0.026441697602184976, 'AP_small': 0.010583883892274994, 'AP_m': 0.044976540581496194, 'AP_l': 0.0756733533889817}\n",
        "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
        "```\n",
        "## Results total_epochs=20\n",
        "```\n",
        "Comments:\n",
        "-  based on nanodet/config/nanodet-plus-m-1.5x_416.yml\n",
        "-  \"device\": settings for colab T4 GPU\n",
        "-  \"total_epochs\": set to 20 during testing, default 300\n",
        "...\n",
        "[NanoDet][05-16 09:25:43]INFO:\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
        " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
        " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
        "\n",
        "[NanoDet][05-16 09:25:43]INFO:\n",
        "| class            | AP50   | mAP   | class     | AP50   | mAP   |\n",
        "|:-----------------|:-------|:------|:----------|:-------|:------|\n",
        "| Safety-Equipment | nan    | nan   | Person    | 86.4   | 49.3  |\n",
        "| goggles          | 35.7   | 15.4  | helmet    | 86.0   | 46.3  |\n",
        "| no-goggles       | 42.6   | 16.6  | no-helmet | 34.2   | 13.8  |\n",
        "| no-vest          | 59.6   | 26.3  | vest      | 82.5   | 42.8  |\n",
        "[NanoDet][05-16 09:25:44]INFO:Saving model to workspace/nanodet-plus-m-1.5x_416-ppe/model_best/nanodet_model_best.pth\n",
        "[NanoDet][05-16 09:25:44]INFO:Val_metrics: {'mAP': 0.3006027561087712, 'AP_50': 0.6099170448933922, 'AP_75': 0.2496291506747232, 'AP_small': 0.07788513248169772, 'AP_m': 0.212229159695, 'AP_l': 0.36198435595574324}\n",
        "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
        "\n",
        "real\t21m35.722s\n",
        "user\t25m48.699s\n",
        "sys\t6m6.849s\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nanodet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
